# ğŸŒ¤ï¸ Toetrandro-etl â€” Travel Recommendation Based on Climate

## ğŸ§­ Project Overview

**Toetrandro-etl** is a full-stack ETL and analytics pipeline that collects, processes, and visualizes weather data to answer a real-world question:

> ğŸ—ºï¸ *When is the best time to visit a city based on weather conditions?*

This project combines automation, data modeling, and interactive dashboards to deliver actionable travel recommendations based on real-time and historical climate data.

---

## ğŸ¯ Project Goals

- ğŸ“¦ Automate daily ETL workflows using Apache Airflow  
- ğŸŒ Integrate real-time and historical weather data  
- ğŸ§¼ Clean and model data for climate-based travel scoring  
- ğŸ“Š Visualize insights through an interactive dashboard  

---

## ğŸŒ Use Case: Climate & Tourism

### â“ Problem Statement

> Can we recommend the best times to visit a city based on weather comfort?

### ğŸ“ˆ Key Metrics

- âœ… Ideal temperature range (e.g., 22Â°Câ€“28Â°C)  
- ğŸŒ§ï¸ Low precipitation and wind speed  
- ğŸ“… Monthly comfort scores and ideal day counts  

---

## âš™ï¸ Technical Stack

| Layer         | Tools/Technologies Used           |
|---------------|-----------------------------------|
| Automation    | Apache Airflow                    |
| Data Handling | Python, Pandas, GeoCoder          |
| Data Sources  | OpenWeather API, CSV/OpenMeteo    |
| Visualization | Jupyter Notebooks, Metabase       |
| Orchestration | DAGs with task-based architecture |

---

## ğŸ› ï¸ Key Features

- ğŸ“¡ **Daily automated extraction** of weather data  
- ğŸ“‚ **Historical dataset integration** (CSV, APIs)  
- ğŸ”„ **ETL pipeline** with modular Airflow tasks: `extract`, `transform`, `merge`, `migrate`  
- ğŸ§½ **Data cleaning & normalization** for schema consistency  
- ğŸŒŸ **Star schema modeling** for analytics-ready structure  
- ğŸ“Š **Interactive dashboard** with filters by city, month, and metric  

---

## ğŸ“ Repository Structure

```
toetrandro-etl/
â”œâ”€â”€ workflows/
â”‚   â”œâ”€â”€ dags/                   # Airflow DAGs
â”‚   â”œâ”€â”€ scripts/                # Task logic
â”‚   â””â”€â”€ config/                 # Airflow variables/settings
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Raw extracted data
â”‚   â”œâ”€â”€ merged/                 # Final merged dataset
â”‚   â””â”€â”€ processed/              # Cleaned, transformed data
â”œâ”€â”€ notebooks/                  # Jupyter Notebooks for EDA & modeling
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                    # OpenWeather API client
â”‚   â”œâ”€â”€ core/                   # ETL logic
â”‚   â””â”€â”€ utils/                  # Logging, helpers
â”œâ”€â”€ tests/                      # Unit tests
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md
```

---

## ğŸ” Pipeline Logic (Airflow DAG)

1. **establish_city_config** â€“ Defines cities and config  
2. **extract_weather_data** â€“ Pulls real-time weather from OpenWeather API  
3. **transform_enriched_data** â€“ Cleans and enriches the dataset  
4. **merge_processed_files** â€“ Combines historical and real-time data  
5. **migrate_data_to_postgres** â€“ Loads data into a star schema in PostgreSQL  

---

## ğŸ“š Additional Documentation

Detailed documentation is available in the [`doc`](doc) folder:

- ğŸ§± [Pipeline Process](doc/process/process_doc.md) â€” Detailed breakdown of each ETL step  
- ğŸŒ¬ï¸ [Airflow Configuration](doc/process/airflow_env.md) â€” Airflow variables and environment setup  
- ğŸ“Š [Model Documentation](doc/data/model_doc.md) â€” About how the model is design (**Star schema model**)

---

## ğŸ“Š Dashboard Overview

The Toetrandro dashboard is designed to answer two complementary questions:

---

### ğŸŒ Global View: *Where and when is the best place to travel?*

![Global_Toetrandro Dashboard](doc/dashboard/global.png)

This view provides a high-level comparison across all cities and time periods. It answers:

- ğŸ† Which city has the highest annual comfort score?  
- ğŸ“… How many ideal days were recorded across all cities?  
- ğŸŒŸ Which cities are best to visit overall?  
- ğŸ“† Which months are most comfortable for travel?  
- â„ï¸ How does seasonal comfort vary by city?  

> This global perspective helps travelers compare destinations and choose the best months to travel based on aggregated climate comfort.

---

### ğŸ™ï¸ Local View: *Whatâ€™s the best time to visit a specific city?*

![Local_Toetrandro_Dashboard](doc/dashboard/local.png)

This city-specific dashboard allows users to select a city, month, and year to explore detailed comfort trends. It answers:

- ğŸ“Œ What is the most ideal month to visit this city?  
- ğŸ“… How many ideal days occurred in the selected year?  
- ğŸ“Š What proportion of days were ideal vs. not ideal?  
- ğŸ“ˆ How has the comfort score evolved over the years?  
- ğŸ”„ How does the number of ideal days change month by month?  
- ğŸ•°ï¸ Is the city becoming more or less comfortable over time?  

> For example, selecting **Mahajanga** in **2025** reveals:  
> - âœ… June is the most ideal month  
> - ğŸ“… 26 ideal days recorded that year  
> - ğŸ“Š 40.4% of days were ideal  
> - ğŸ“ˆ A steady increase in comfort score from 2020 to 2025  
> - ğŸ”„ Monthly breakdown showing June peaking with 12 ideal days  

---

## ğŸ§ª Testing & Reliability

- âœ… Unit tests for all ETL components  
- ğŸ” Retry logic and logging in Airflow tasks  
- ğŸ” Secure API key handling via Airflow Variables  

---

## ğŸš€ Getting Started

1. **Clone the repository**  
   ```bash
   git clone https://github.com/Abega1642/toetrandro-etl.git
   ```

2. **Install dependencies**  
   ```bash
   pip install -r requirements.txt
   ```

3. **Set environment variables**  
   Follow the instructions in [airflow_env.md](doc/process/airflow_env.md)

---

> â€¼ï¸ IMPORTANT NOTE : before you run the DAG, make sure you have the PostgreSQL database set up, with correct credentials, database and table. Details on the tables can be found in the file indicated below.
> Make sure to have the database correctly set-up !

Script name: [toetrandro_db_scipt.sql](../../migration/toetrandro_db_script.sql)

---

4. **Initialize Airflow**  
   ```bash
   airflow db init
   airflow users create --username admin ...
   ```

5. **Launch Airflow**  
   ```bash
   airflow scheduler &
   airflow api-server &
   airflow dag-processor
   ```

---

## ğŸ“Œ Future Improvements

- ğŸŒ Add more cities and weather APIs  
- ğŸ—ºï¸ Enhance dashboard with maps and geospatial filters  
- ğŸ³ Dockerize the pipeline for easier deployment  

---

## ğŸ‘¥ Author

- **AbegÃ  Razafindratelo**

---

## ğŸ“„ License

This project is licensed under the MIT License.
